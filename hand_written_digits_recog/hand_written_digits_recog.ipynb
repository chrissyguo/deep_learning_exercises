{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbe789ce430>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREPARING THE DATASET\n",
    "## Hyper parameters\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enable = False\n",
    "torch.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load MNIST dataset in a handy way\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dsets.MNIST('/home/bdggj/Documents/Deep_learning_exercise/hand_written_digits_recog/files/', train=True, download=True, \n",
    "                transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                              transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                             ])),\n",
    "    batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dsets.MNIST('/home/bdggj/Documents/Deep_learning_exercise/hand_written_digits_recog/files/', train=False, download=True, \n",
    "                transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                              transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                             ])),\n",
    "    batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## examples\n",
    "\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## show some pics\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING THE NETWORK\n",
    "\n",
    "# 3-D convolutional layers followed by two fully-connected layers\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)  #flat the features from (20, 4, 4) to (1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = Net()\n",
    "network.cuda() # use a GPU ofr training\n",
    "print(network)\n",
    "\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, \n",
    "                     momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING THE MODEL\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data=data.cuda()\n",
    "        target=target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)  #calculate the negative log likeligood loss\n",
    "        loss.backward()\n",
    "        optimizer.step() #renew the parameters\n",
    "        if batch_idx % log_interval == 0:\n",
    "             print ('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "             epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "             100. *batch_idx / len(train_loader), loss.item()))\n",
    "        \n",
    "             train_losses.append(loss.item())\n",
    "             train_counter.append(\n",
    "                 (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "             torch.save(network.state_dict(), \n",
    "                        '/home/bdggj/Documents/Deep_learning_exercise/hand_written_digits_recog/results/model.pth')\n",
    "             torch.save(optimizer.state_dict(), \n",
    "                        '/home/bdggj/Documents/Deep_learning_exercise/hand_written_digits_recog/results/optimizer.pth')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data=data.cuda()\n",
    "            target=target.cuda()\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1].cuda()\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bdggj/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3004, Accuracy: 751/10000 (7%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.278280\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.279660\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.263015\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.256495\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.301418\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.188039\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.182298\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.073817\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.031979\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.079804\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.931658\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.736195\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.908807\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.755384\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.446099\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.505101\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.325090\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.453677\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.301913\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.268132\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.080043\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.402216\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.069205\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.950108\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.124539\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.268830\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.043346\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.974475\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.830362\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.840258\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.918204\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.753132\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.815146\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.887500\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.911798\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.935255\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.950226\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.858115\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.736018\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.880559\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.806511\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.692312\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.767785\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.771350\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.139645\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.880235\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.606886\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 1.219762\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.767308\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.794706\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.648027\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.509996\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.795398\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.580858\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.778919\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.551454\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.616915\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.483111\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.593221\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.516400\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.722249\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.632698\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.477152\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.789405\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.581148\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.392586\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.613707\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.448107\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.804145\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.497334\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.615045\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.601457\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.729952\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.833286\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.523538\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.346373\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.414078\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.616813\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.390641\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.517965\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.520752\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.434434\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.773916\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.622496\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.572488\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.548920\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.510056\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.529424\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.513181\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.592391\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.416034\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.439283\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.552778\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.337939\n",
      "\n",
      "Test set: Avg. loss: 0.2053, Accuracy: 9430/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.335906\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.463652\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.545946\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.469537\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.618441\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.418952\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.569107\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.423702\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.363989\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.482835\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.574098\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.404782\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.416647\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.406896\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.517348\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.400549\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.430863\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.558348\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.473468\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.559924\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.429099\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.332353\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.342694\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.528447\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.352261\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.373743\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.258296\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.273573\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.372785\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.378146\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.415779\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.438206\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.500169\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.491314\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.267414\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.413583\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.474502\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.657122\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.284171\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.221639\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.403131\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.494606\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.333569\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.281078\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.586400\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.496644\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.445888\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.240569\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.537918\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.479011\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.368562\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.413709\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.261804\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.332289\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.440759\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.348683\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.351158\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.376932\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.290945\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.325639\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.371107\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.224326\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.316646\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.473772\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.731824\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.446781\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.319730\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.209025\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.317356\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.349582\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.200157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.383572\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.589600\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.709626\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.427140\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.416961\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.345559\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.177977\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.273763\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.252160\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.392428\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.307067\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.329433\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.252385\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.413544\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.482838\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.422406\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.570844\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.579955\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.397591\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.196537\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.257277\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.512316\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.605291\n",
      "\n",
      "Test set: Avg. loss: 0.1225, Accuracy: 9631/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.408657\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.363684\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.296806\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.445730\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.615010\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.338792\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.348857\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.475209\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.375577\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.372839\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.273703\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.351689\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.239856\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.198144\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.198903\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.371159\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.462863\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.378427\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.227024\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.386404\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.307808\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.290227\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.329341\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.350694\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.338831\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.262034\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.396264\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.181378\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.454440\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.297719\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.246457\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.264686\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.378688\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.189222\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.239636\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.334321\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.363559\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.267547\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.226526\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.243084\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.271027\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.276288\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.194092\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.126554\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.467227\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.442057\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.455157\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.380165\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.228710\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.442628\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.302014\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.419426\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.401046\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.216438\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.416083\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.514189\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.333489\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.246496\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.185964\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.328735\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.424753\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.149685\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.230261\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.287061\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.407049\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.340986\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.477811\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.317597\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.500267\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.284081\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.271217\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.212671\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.236508\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.274676\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.307453\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.344370\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.215550\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.215608\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.154408\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.124100\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.211410\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.323773\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.355810\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.242178\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.202324\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.366480\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.295292\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.280812\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.222324\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.179190\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.529200\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.411351\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.455742\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.407500\n",
      "\n",
      "Test set: Avg. loss: 0.0988, Accuracy: 9700/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.361503\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.285796\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.343858\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.450522\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.213097\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.186984\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.353168\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.286512\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.200593\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.374231\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.395641\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.169740\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.300010\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.337143\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.206861\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.358719\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.543791\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.196971\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.208465\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.408907\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.203751\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.338883\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.235739\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.222563\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.236923\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.288089\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.235770\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.304412\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.173500\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.141297\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.275646\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.291779\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.106367\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.150916\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.189165\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.268824\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.330573\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.187481\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.289957\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.334960\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.166778\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.359907\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.356610\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.229842\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.165624\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.239928\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.249873\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.238550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.281502\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.508788\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.217840\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.251055\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.315807\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.333552\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.248828\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.232396\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.305835\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.189531\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.140490\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.146731\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.120886\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.135887\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.405184\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.301903\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.133994\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.236252\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.171050\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.365364\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.264774\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.370372\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.201188\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.215855\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.452910\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.105620\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.274834\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.255141\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.282158\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.364345\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.341733\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.136510\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.152798\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.167880\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.248831\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.109329\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.130095\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.428311\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.286931\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.160254\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.239762\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.532575\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.156416\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.221995\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.514283\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.205688\n",
      "\n",
      "Test set: Avg. loss: 0.0832, Accuracy: 9736/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.213697\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.374979\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.588977\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.264158\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.230375\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.153458\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.267854\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.254031\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.190116\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.159101\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.153783\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.260801\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.254720\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.268883\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.258635\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.192718\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.211123\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.229440\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.069896\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.202160\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.439444\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.300273\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.319112\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.185916\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.121182\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.283693\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.327210\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.088359\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.314941\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.151757\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.253685\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.242910\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.284828\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.156971\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.251023\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.194677\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.381488\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.317877\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.271874\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.110770\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.282646\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.267092\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.384895\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.131929\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.156879\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.188854\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.263635\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.126700\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.233491\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.164301\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.455298\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.198759\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.250198\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.172782\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.162988\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.272297\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.358564\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.157365\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.138816\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.212793\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.269796\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.163209\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.169819\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.235876\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.193014\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.190343\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.220959\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.149388\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.260052\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.279661\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.414960\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.083913\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.500642\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.279566\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.267286\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.263495\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.180833\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.190623\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.206387\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.273832\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.157408\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.265602\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.089934\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.187472\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.111083\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.331757\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.147420\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.247644\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.167945\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.163228\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.245040\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.262531\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.271437\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.174730\n",
      "\n",
      "Test set: Avg. loss: 0.0748, Accuracy: 9769/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
